{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7gD2_k5YYW9R"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBGNraktLcWe",
        "outputId": "73998436-a8cb-4904-9b81-d2eaa0ef25ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Dec 16 03:20:56 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P0              42W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yRIhS6lOTYX",
        "outputId": "fda387d1-1f48-41ba-f429-7acfc3c7ee3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets==3.1.0 in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.1.0) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets==3.1.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.1.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.1.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==3.1.0) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.1.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.1.0) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.1.0) (1.16.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.4.1+cu121)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install datasets==3.1.0\n",
        "# #load_dataset sometimes hangs on a higher version\n",
        "! pip install transformers accelerate evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip /content/data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkZIjE-fLltK",
        "outputId": "5d3e7d65-0332-4d4f-af16-f485ace3d08c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/data.zip\n",
            "replace data/all_dev.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace data/all_train.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JifsBqXxmtqm"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OjX3Y-kCzdpE"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForQuestionAnswering, AutoModelForQuestionAnswering, AutoTokenizer\n",
        "from accelerate import Accelerator\n",
        "from tqdm import tqdm\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_scheduler\n",
        "from evaluate import EvaluationModule\n",
        "from evaluate import load as load_metric\n",
        "from torch.optim import Optimizer\n",
        "\n",
        "# we set up some seeds so that we can reproduce results\n",
        "seed = 123\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## loading dataset"
      ],
      "metadata": {
        "id": "zlNOwOZPH-Jb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(folder_path: str):\n",
        "    data_files = {\"train\": os.path.join(folder_path, \"all_train.json\"), \"dev\": os.path.join(folder_path, \"all_dev.json\")}\n",
        "    dataset = load_dataset('json', data_files=data_files)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "L8j4JtSgSUdL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eMoGcjRgMk1E"
      },
      "outputs": [],
      "source": [
        "# Change train.json / dev.json to the appropriate filepaths =====\n",
        "# folder_path = \"/content/drive/MyDrive/ComputationalLinguistics/Final\"\n",
        "folder_path = \"/content/data\"\n",
        "# loading dataset\n",
        "data_files = {\"train\": os.path.join(folder_path, \"all_train.json\"), \"dev\": os.path.join(folder_path, \"all_dev.json\")}\n",
        "# loading dataset\n",
        "dataset = load_dataset('json', data_files=data_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0gx_15a_cWE7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7dbfc61-6d0b-43c4-ad53-6284c50c7882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# defining model and tokenizer\n",
        "def load_model(model_name: str):\n",
        "    tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
        "    bert_model = DistilBertForQuestionAnswering.from_pretrained(model_name).to(device)\n",
        "    return bert_model, tokenizer\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
        "bert_model = DistilBertForQuestionAnswering.from_pretrained(model_name).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## constructing dataset class"
      ],
      "metadata": {
        "id": "UUz4labiIB74"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5U85PRjRdfeN"
      },
      "outputs": [],
      "source": [
        "# defining dataset class for dataloaders\n",
        "class QADataset(Dataset):\n",
        "    def __init__(self, data: list, tokenizer: AutoTokenizer, max_length: int = 512):\n",
        "        \"\"\"\n",
        "        data: list\n",
        "            list of json objects\n",
        "        tokenizer: AutoTokenizer\n",
        "            tokenizer for the model\n",
        "        max_length: int\n",
        "            max length of the input\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # get elements in each sample\n",
        "        # each sample is in json's format\n",
        "        example = self.data[idx]\n",
        "        question = example['questions'][0]['input_text'] # str\n",
        "        context = example['contexts'] # str\n",
        "        answer = example['answers'][0] # dict: span_start, span_end, answer string...\n",
        "        # Tokenize question and context together => [CLS]<question tokens>[SEP]<context tokens>[SEP][PAD]...\n",
        "        inputs = self.tokenizer(\n",
        "            question,\n",
        "            context,\n",
        "            truncation=\"only_second\",\n",
        "            max_length=self.max_length,\n",
        "            # offset mapping helps us map tokens back to a word\n",
        "            return_offsets_mapping=True,\n",
        "            padding=\"max_length\",\n",
        "            # return_token_type_ids=True\n",
        "        )\n",
        "        \"\"\"\n",
        "        offsets: list\n",
        "            [(i, j), ... ]\n",
        "            each n-th item in the list is a tuple, corresponding to the n-th token in an encoded sequence\n",
        "            i = start position of the token in the original sequence\n",
        "            j = end position of the token in the original sequence\n",
        "        \"\"\"\n",
        "        offsets = inputs.pop('offset_mapping')\n",
        "        start_char = answer[\"span_start\"]\n",
        "        end_char = answer[\"span_end\"]\n",
        "        sequence_ids = inputs.sequence_ids(0)\n",
        "        # getting context's position\n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        context_start = idx\n",
        "        while sequence_ids[idx] == 1:\n",
        "            idx += 1\n",
        "        context_end = idx - 1\n",
        "        # If the answer is not inside the context, or, unanswerable (-1, -1), label it (0, 0)\n",
        "        if start_char == -1 or end_char == -1 or offsets[context_start][0] > end_char or offsets[context_end][1] < start_char:\n",
        "            inputs[\"start_positions\"] = 0\n",
        "            inputs[\"end_positions\"] = 0\n",
        "            inputs['answer_type'] = 0\n",
        "        else:\n",
        "            # source: https://huggingface.co/docs/transformers/tasks/question_answering\n",
        "            # Otherwise it's the start and end token positions\n",
        "            idx = context_start\n",
        "            # go with an index-ascending way: context_start, context_start + 1...\n",
        "            while idx <= context_end and offsets[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            inputs[\"start_positions\"] = idx - 1\n",
        "            idx = context_end\n",
        "            # go with an index-descending way: context_end, context_end - 1...\n",
        "            while idx >= context_start and offsets[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            inputs[\"end_positions\"] = idx + 1\n",
        "            inputs['answer_type'] = 1\n",
        "        \"\"\"\n",
        "        {\n",
        "            \"inpud_ids\":<inpud_ids>,\n",
        "            \"attention_mask\":<attention_mask>,\n",
        "            \"start_positions\":<start_position>,\n",
        "            \"end_positions\":<end_position>,\n",
        "            \"answer_type\":<answer_type>\n",
        "        }\n",
        "        \"\"\"\n",
        "        return {k:torch.tensor(v) for k, v in inputs.items()}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## building up dataloaders"
      ],
      "metadata": {
        "id": "kv9Aat0LIHza"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6DU3jaOkcNfo"
      },
      "outputs": [],
      "source": [
        "# defining datasets and dataloaders\n",
        "def load_dataloader(dataset: dict, tokenizer: AutoTokenizer, batch_size: int = 32):\n",
        "    train_dataset = QADataset(dataset['train'], tokenizer)\n",
        "    validation_dataset = QADataset(dataset['dev'], tokenizer)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size)\n",
        "    return train_dataloader, validation_dataloader\n",
        "\n",
        "batch_size = 32\n",
        "train_dataset = QADataset(dataset['train'], tokenizer)\n",
        "validation_dataset = QADataset(dataset['dev'], tokenizer)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model-related Preparation for Training and Validation"
      ],
      "metadata": {
        "id": "BPUd4NNEAv0U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating joint model class\n",
        "\n",
        "The class of QuestionAnsweringWithTypePrediction will predict three things: start positions, end positions, and answer types. Start positions and end positions are predicted through BERT-based QA models, while answer types are predicted by a linear classifier.\n",
        "\n",
        "BERT models returns logits for the two positions, each with the shape of (batch size,  input dimension). The classifer takes the last hidden representation of [CLS] as input and returns logits of (batch size, # of answer type)."
      ],
      "metadata": {
        "id": "QLBgkEFBIOuq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NmJlVZUFvvzv"
      },
      "outputs": [],
      "source": [
        "# Model that predics spans and answer types\n",
        "class QuestionAnsweringWithTypePrediction(nn.Module):\n",
        "    def __init__(self, pretrained_model: AutoModelForQuestionAnswering, answer_type: int = 2):\n",
        "        \"\"\"\n",
        "        pretrained_model: AutoModelForQuestionAnswering\n",
        "            pretrained model for question answering\n",
        "        answer_type: int\n",
        "            number of answer types\n",
        "        \"\"\"\n",
        "        super(QuestionAnsweringWithTypePrediction, self).__init__()\n",
        "        self.bert_qa = pretrained_model.from_pretrained(model_name)\n",
        "        self.type_classifier = nn.Linear(self.bert_qa.config.hidden_size, answer_type)  # Binary classification head\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids=None, start_positions=None, end_positions=None):\n",
        "        \"\"\"\n",
        "        input_ids: torch.Tensor\n",
        "            input ids for the model\n",
        "        attention_mask: torch.Tensor\n",
        "            attention mask for the model\n",
        "        token_type_ids: torch.Tensor\n",
        "            token type ids for the model\n",
        "        start_positions: torch.Tensor\n",
        "            start positions for the model\n",
        "        end_positions: torch.Tensor\n",
        "            end positions for the model\n",
        "        \"\"\"\n",
        "        outputs = self.bert_qa(\n",
        "            input_ids, attention_mask=attention_mask,\n",
        "            # token_type_ids=token_type_ids,\n",
        "            start_positions = start_positions, end_positions = end_positions, output_hidden_states=True\n",
        "        )\n",
        "        # get the representation of [CLS] from the last hidden state\n",
        "        pooled_output = outputs.hidden_states[-1][:, 0, :]\n",
        "        # get the output logits of linear classifier\n",
        "        type_logits = self.type_classifier(pooled_output)\n",
        "        # returning logits for loss calculation\n",
        "        return {\n",
        "            \"start_logits\": outputs.start_logits,\n",
        "            \"end_logits\": outputs.end_logits,\n",
        "            \"type_logits\": type_logits\n",
        "        }\n",
        "# loss term according to the paper\n",
        "class Loss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Loss, self).__init__()\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "    def forward(self, start_logits, end_logits, type_logits, start_positions, end_positions, type_labels):\n",
        "        \"\"\"\n",
        "        start_logits: torch.Tensor\n",
        "            start logits for the model\n",
        "        end_logits: torch.Tensor\n",
        "            end logits for the model\n",
        "        type_logits: torch.Tensor\n",
        "            type logits for the model\n",
        "        \"\"\"\n",
        "        # # get softmax of the logits\n",
        "        # # log_softmax is a compound function, more stable than -log(softmax()) numericaly\n",
        "        # loss_start = -nn.functional.log_softmax(start_logits, dim = -1)[:, start_positions]\n",
        "        # loss_end = -nn.functional.log_softmax(end_logits, dim = -1)[:, end_positions]\n",
        "        # loss_type = -nn.functional.log_softmax(type_logits, dim = -1)[:, type_labels]\n",
        "        # return loss_start.mean() + loss_end.mean() + loss_type.mean()\n",
        "        # # This one does not works! Not sure why...\n",
        "        # # nearly all predictions of position are index 0\n",
        "\n",
        "\n",
        "        # This one works!\n",
        "        loss_start = self.loss_fn(start_logits, start_positions)\n",
        "        loss_end = self.loss_fn(end_logits, end_positions)\n",
        "        loss_type = self.loss_fn(type_logits, type_labels)\n",
        "        return loss_start + loss_end + loss_type"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## evaluation functions"
      ],
      "metadata": {
        "id": "WRy99Om2aEoT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QZsRj_7M642W"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, loss_fn, device):\n",
        "    \"\"\"\n",
        "    Evaluate a question-answering model on precision, recall, and F1 score.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    model : torch.nn.Module\n",
        "        The model to evaluate: QuestionAnsweringWithTypePrediction\n",
        "    dataloader : torch.utils.data.DataLoader\n",
        "        DataLoader for test data.\n",
        "    loss_fn : nn.Module\n",
        "        Loss function for evaluation.\n",
        "    device : torch.device\n",
        "        The device for computation.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict\n",
        "        Average loss\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Validation Progress\", total=len(dataloader), leave=True, ncols=100):\n",
        "            # Move batch to device\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            start_positions = batch['start_positions'].to(device)\n",
        "            end_positions = batch['end_positions'].to(device)\n",
        "            answer_type = batch['answer_type'].to(device)\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
        "            start_logits = outputs[\"start_logits\"]\n",
        "            end_logits = outputs[\"end_logits\"]\n",
        "            type_logits = outputs[\"type_logits\"]\n",
        "            # Calculate loss\n",
        "            loss = loss_fn(\n",
        "                start_logits, end_logits, type_logits,\n",
        "                start_positions, end_positions, answer_type\n",
        "            )\n",
        "            total_loss += loss.item()\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    return {\n",
        "        \"loss\": avg_loss,\n",
        "    }\n",
        "\n",
        "def calculate_f1_precision_recall(y_pred, y_true):\n",
        "    \"\"\"\n",
        "    Calculate precision, recall, and F1 score.\n",
        "    Parameters:\n",
        "    -----------\n",
        "    y_pred : str\n",
        "        Predicted string.\n",
        "    y_true : str\n",
        "        True string.\n",
        "    Returns:\n",
        "    --------\n",
        "    tuple\n",
        "        Precision, recall, and F1 score\n",
        "    \"\"\"\n",
        "    # Calculate overlap\n",
        "    y_pred = y_pred.split()\n",
        "    y_true = y_true.split()\n",
        "    pred_tokens = set(y_pred)\n",
        "    true_tokens = set(y_true)\n",
        "    common_tokens = pred_tokens & true_tokens\n",
        "    # Precision and recall\n",
        "    precision = len(common_tokens) / len(pred_tokens) if pred_tokens else 0.0\n",
        "    recall = len(common_tokens) / len(true_tokens) if true_tokens else 0.0\n",
        "    # F1 score\n",
        "    if precision + recall > 0:\n",
        "        f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    else:\n",
        "        f1 = 0.0\n",
        "    return precision, recall, f1\n",
        "\n",
        "def get_prediction_score(model, tokenizer, dataloader, device):\n",
        "    \"\"\"\n",
        "    Evaluate a question-answering model on precision, recall, and F1 score.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    model : torch.nn.Module\n",
        "        The model to evaluate.\n",
        "    dataloader : torch.utils.data.DataLoader\n",
        "        DataLoader for test data.\n",
        "    loss_fn : nn.Module\n",
        "        Loss function for evaluation.\n",
        "    device : torch.device\n",
        "        The device for computation.\n",
        "    Returns:\n",
        "    --------\n",
        "    dict\n",
        "        Average loss\n",
        "    \"\"\"\n",
        "    predictions = {\"precision\":[], \"recall\":[], \"f1\":[]}\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Validation Progress\", total=len(dataloader), leave=True, ncols=100):\n",
        "            # Move batch to device\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            start_positions = batch['start_positions'].to(device)\n",
        "            end_positions = batch['end_positions'].to(device)\n",
        "            answer_type = batch['answer_type'].to(device)\n",
        "            context_length = input_ids.size(1)\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
        "            start_logits = outputs[\"start_logits\"]\n",
        "            end_logits = outputs[\"end_logits\"]\n",
        "            # type_logits = outputs[\"type_logits\"].argmax(dim=-1)\n",
        "            for i in range(len(start_logits)):\n",
        "                pred_start = start_logits[i].argmax(dim=-1).item()\n",
        "                pred_end = end_logits[i].argmax(dim=-1).item()\n",
        "                # making sure no out-of-bound indices\n",
        "                pred_start, pred_end = max(0, pred_start), min(pred_end, end_logits.size(-1))\n",
        "                # making sure start <= end\n",
        "                pred_start, pred_end = min(pred_start, pred_end), max(pred_start, pred_end)\n",
        "                # getting ground positions\n",
        "                true_start, true_end = start_positions[i].item(), end_positions[i].item()\n",
        "                # converting ids to tokens\n",
        "                y_pred = tokenizer.convert_ids_to_tokens(input_ids[i][pred_start:(pred_end + 1)])\n",
        "                y_pred = tokenizer.convert_tokens_to_string(y_pred)\n",
        "                # converting tokens back to strings\n",
        "                y_true = tokenizer.convert_ids_to_tokens(input_ids[i][true_start:(true_end + 1)])\n",
        "                y_true = tokenizer.convert_tokens_to_string(y_true)\n",
        "                # calculating scores\n",
        "                precision, recall, f1 = calculate_f1_precision_recall(y_pred, y_true)\n",
        "                predictions[\"precision\"].append(precision)\n",
        "                predictions[\"recall\"].append(recall)\n",
        "                predictions[\"f1\"].append(f1)\n",
        "    predictions = {key:(sum(value) / dataloader.dataset.__len__()) for key, value in predictions.items()}\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train function"
      ],
      "metadata": {
        "id": "0Y0t1wUVaJF-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aV9jWDXF78m6"
      },
      "outputs": [],
      "source": [
        "def train(model: torch.nn.Module,\n",
        "          optimizer: Optimizer,\n",
        "          num_epochs: int,\n",
        "          train_dataloader: DataLoader,\n",
        "          validation_dataloader: DataLoader,\n",
        "          loss_fn: nn.Module,\n",
        "          lr_scheduler: torch.optim.lr_scheduler.LambdaLR,\n",
        "          device: torch.device,\n",
        "          accum_iter: int,\n",
        "          accelerator: Accelerator\n",
        "          ) -> None:\n",
        "    \"\"\"\n",
        "    Trains a model by performing forward passes and backpropagating on batches to optimize loss.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    model : torch.nn.Module\n",
        "        The model to be trained.\n",
        "    optimizer : torch.optim.Optimizer\n",
        "        The training optimizer.\n",
        "    num_epochs : int\n",
        "        Number of epochs to train for.\n",
        "    train_dataloader : DataLoader\n",
        "        DataLoader containing training examples.\n",
        "    validation_dataloader : DataLoader\n",
        "        DataLoader containing validation examples.\n",
        "    loss_fn : nn.Module\n",
        "        Loss function for evaluation.\n",
        "    accum_iter : int\n",
        "        Number of steps to accumulate gradients before updating weights.\n",
        "    lr_scheduler : torch.optim.lr_scheduler.LambdaLR\n",
        "        Learning rate scheduler.\n",
        "    device : torch.device\n",
        "        The device that the training will be performed on.\n",
        "    accelerator: Accelerator\n",
        "        The accelerator for distributed training.\n",
        "    \"\"\"\n",
        "    print(\"Training begins...\")\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_metrics = {\"loss\":0.0}\n",
        "        for batch_idx, batch in tqdm(enumerate(train_dataloader), desc=\"Training Progress\", total=len(train_dataloader), leave=True, ncols=100):\n",
        "            # getting elements of the batch\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            start_positions = batch['start_positions'].to(device)\n",
        "            end_positions = batch['end_positions'].to(device)\n",
        "            answer_type = batch['answer_type'].to(device)\n",
        "            # model prediction: start_logits, end_logits, type_logits\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
        "            loss = loss_fn(\n",
        "                outputs[\"start_logits\"], outputs[\"end_logits\"], outputs[\"type_logits\"],\n",
        "                start_positions, end_positions, answer_type\n",
        "            )\n",
        "            accelerator.backward(loss)\n",
        "            # gradient accumulation technique, helping reducing memory load\n",
        "            if ((batch_idx + 1) % accum_iter == 0) or (batch_idx + 1 == len(train_dataloader)):\n",
        "                optimizer.step()\n",
        "                lr_scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "            train_metrics[\"loss\"] += loss.item()\n",
        "        # display current result\n",
        "        print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "        print(\"Training\")\n",
        "        for key in train_metrics.keys():\n",
        "            train_metrics[key] /= len(train_dataloader.dataset)\n",
        "            print(f\"{key}: {train_metrics[key]:>3f}\")\n",
        "        print()\n",
        "        print(\"Validation\")\n",
        "        val_metrics = evaluate(model=model, dataloader=validation_dataloader, loss_fn=loss_fn, device=device)\n",
        "        print()\n",
        "        for key in val_metrics.keys():\n",
        "            print()\n",
        "            print(f\"{key}: {val_metrics[key]:>3f}\")\n",
        "        print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Instantiation and Training"
      ],
      "metadata": {
        "id": "p8jqmaklaNoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = QuestionAnsweringWithTypePrediction(bert_model).to(device)\n",
        "\n",
        "# baseline, no training\n",
        "score_baseline = get_prediction_score(model, tokenizer, validation_dataloader, device)\n",
        "print()\n",
        "print(f\"precision: {score_baseline['precision']:>3f}\")\n",
        "print(f\"recall: {score_baseline['recall']:>3f}\")\n",
        "print(f\"f1: {score_baseline['f1']:>3f}\")"
      ],
      "metadata": {
        "id": "oohGMZkBGWkA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21e67b24-cb1c-4114-9125-91bdf831f1c4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Validation Progress: 100%|██████████████████████████████████████████| 55/55 [00:32<00:00,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "precision: 0.048043\n",
            "recall: 0.246843\n",
            "f1: 0.064559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zIo52mC8hB_D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ced6409-5042-4bda-bc41-9c94c241db2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training begins...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████████████████████████████████████| 871/871 [08:18<00:00,  1.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "Training\n",
            "loss: 0.168507\n",
            "\n",
            "Validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Progress: 100%|██████████████████████████████████████████| 55/55 [00:11<00:00,  4.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "loss: 3.185933\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████████████████████████████████████| 871/871 [08:19<00:00,  1.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2\n",
            "-------------------------------\n",
            "Training\n",
            "loss: 0.081466\n",
            "\n",
            "Validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Progress: 100%|██████████████████████████████████████████| 55/55 [00:11<00:00,  4.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "loss: 2.759846\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_path = os.path.join(folder_path, \"model_state_dict.pth\")\n",
        "if os.path.exists(model_path):\n",
        "    print(\"loading model from drive\")\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "else:\n",
        "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "    accum_iter = 4\n",
        "    num_epochs = 2\n",
        "    num_training_steps = num_epochs * len(train_dataloader)\n",
        "    lr_scheduler = get_scheduler(\n",
        "        \"linear\",\n",
        "        optimizer = optimizer,\n",
        "        num_warmup_steps = 50,\n",
        "        num_training_steps = num_training_steps\n",
        "    )\n",
        "    # reducing precision to fp16 can forge faster computing on T4\n",
        "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
        "    loss_fn = Loss()\n",
        "    model, optimizer, train_dataloader = accelerator.prepare(model, optimizer, train_dataloader)\n",
        "    train(model, optimizer, num_epochs, train_dataloader, validation_dataloader, loss_fn, lr_scheduler, device, accum_iter, accelerator)\n",
        "    torch.save(model.state_dict(), model_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score_trained = get_prediction_score(model, tokenizer, validation_dataloader, device)\n",
        "print()\n",
        "print(f\"precision: {score_trained['precision']:>3f}\")\n",
        "print(f\"recall: {score_trained['recall']:>3f}\")\n",
        "print(f\"f1: {score_trained['f1']:>3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EY6nOSowXKrC",
        "outputId": "c35b4b51-126a-4b45-f455-601070ce7490"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Progress: 100%|██████████████████████████████████████████| 55/55 [00:11<00:00,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "precision: 0.688941\n",
            "recall: 0.760322\n",
            "f1: 0.683175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: generate figure to compare score_trained and score_baseline, let the legend stays at the bottom, either side is fine\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_scores(score_baseline: dict, score_trained: dict):\n",
        "    metrics = ['precision', 'recall', 'f1']\n",
        "    score_baseline = [score_baseline[metric] for metric in metrics]\n",
        "    score_trained = [score_trained[metric] for metric in metrics]\n",
        "    x = range(len(metrics))\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    width = 0.35\n",
        "    rects1 = ax.bar(x, score_baseline, width, label='Baseline')\n",
        "    rects2 = ax.bar([i + width for i in x], score_trained, width, label='Trained')\n",
        "    ax.set_ylabel('Scores')\n",
        "    ax.set_title('Comparison of Baseline and Trained Model Scores')\n",
        "    ax.set_xticks([i + width / 2 for i in x])\n",
        "    ax.set_xticklabels(metrics)\n",
        "    ax.legend(loc='lower center', bbox_to_anchor=(0.5, -0.15), ncol=2) #legend at the bottom\n",
        "    plt.show()\n",
        "\n",
        "plot_scores(score_baseline, score_trained)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "XeBcND4zI2JB",
        "outputId": "6ab3cdf6-3d59-41c9-c874-782885cf3200"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "a8V3t0JSZ55V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "KS9ZcP-umJLN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "049338e4-5e13-4280-8b39-53924b0d20c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running baseline\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Progress: 100%|██████████████████████████████████████████| 55/55 [00:12<00:00,  4.38it/s]\n",
            "<ipython-input-19-8347008292e9>:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "loading model from drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Progress: 100%|██████████████████████████████████████████| 55/55 [00:10<00:00,  5.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "baseline\n",
            "---------------------------------\n",
            "precision: 0.058903\n",
            "recall: 0.257688\n",
            "f1: 0.074815\n",
            "\n",
            "trained\n",
            "---------------------------------\n",
            "precision: 0.688941\n",
            "recall: 0.760322\n",
            "f1: 0.683175\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def main():\n",
        "    \"\"\"get models and dataloaders\"\"\"\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    # folder_path = \"/content/drive/MyDrive/ComputationalLinguistice/Final\"\n",
        "    folder_path = \"/content/data\"\n",
        "    # getting the dataset\n",
        "    dataset = load_data(folder_path)\n",
        "    # getting the QA model and tokenizer\n",
        "    bert_model, tokenizer = load_model(\"distilbert-base-uncased\")\n",
        "    # getting dataloaders\n",
        "    train_dataloader, validation_dataloader = load_dataloader(dataset, tokenizer)\n",
        "    bert_model = bert_model.to(device)\n",
        "    # getting the target model with the ability to predict start positions, end positions, and answer type\n",
        "    model = QuestionAnsweringWithTypePrediction(bert_model).to(device)\n",
        "    \"\"\"define hypermeter\"\"\"\n",
        "    # Accelerator is our good friend that helps accelerate training progress\n",
        "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
        "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "    # put model, optimizer, and train_dataloader onto accelerator\n",
        "    model, optimizer, train_dataloader = accelerator.prepare(model, optimizer, train_dataloader)\n",
        "    model_path = os.path.join(folder_path, \"model_state_dict.pth\")\n",
        "    \"\"\"model training and inference\"\"\"\n",
        "    # check what our zero-shot model performs\n",
        "    print(\"running baseline\")\n",
        "    score_baseline = get_prediction_score(model, tokenizer, validation_dataloader, device)\n",
        "    print()\n",
        "    # if model exists, load the weights; train the model otherwise.\n",
        "    if os.path.exists(model_path):\n",
        "        print(\"loading model from drive\")\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "    else:\n",
        "        # self-defined loss according to the paper\n",
        "        loss_fn = Loss()\n",
        "        # accumulation step\n",
        "        accum_iter = 4\n",
        "        num_epochs = 2\n",
        "        num_training_steps = num_epochs * len(train_dataloader)\n",
        "        lr_scheduler = get_scheduler(\n",
        "            \"linear\",\n",
        "            optimizer = optimizer,\n",
        "            num_warmup_steps = 50,\n",
        "            num_training_steps = num_training_steps\n",
        "        )\n",
        "        # training begins here\n",
        "        train(model, optimizer, num_epochs, train_dataloader, validation_dataloader, loss_fn, device, accum_iter, accelerator)\n",
        "        # save the model for inference\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "    # check how th model performs after being trained\n",
        "    score_trained = get_prediction_score(model, tokenizer, validation_dataloader, device)\n",
        "    print()\n",
        "    print(\"baseline\")\n",
        "    print(\"---------------------------------\")\n",
        "    print(f\"precision: {score_baseline['precision']:>3f}\")\n",
        "    print(f\"recall: {score_baseline['recall']:>3f}\")\n",
        "    print(f\"f1: {score_baseline['f1']:>3f}\")\n",
        "    print()\n",
        "    print(\"trained\")\n",
        "    print(\"---------------------------------\")\n",
        "    print(f\"precision: {score_trained['precision']:>3f}\")\n",
        "    print(f\"recall: {score_trained['recall']:>3f}\")\n",
        "    print(f\"f1: {score_trained['f1']:>3f}\")\n",
        "    # plot the results\n",
        "    plot_scores(score_baseline, score_trained)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CoXyIORTeu99"
      },
      "execution_count": 18,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}